{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define MariTalk API key and LLM model\n",
    "MARITALK_API_KEY = os.getenv('MARITALK_API_KEY')\n",
    "MARITALK_LLM_MODEL = \"sabia-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant!'), additional_kwargs={})]\n",
      "[HumanMessage(content='Write a document about the basics of data science.', additional_kwargs={}, response_metadata={})]\n",
      "# Introduction to Data Science Basics\n",
      "\n",
      "Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines aspects of statistics, computer science, and domain expertise to analyze data for decision making. Below are the basics of data science that one should understand to embark on this field.\n",
      "\n",
      "## Key Components of Data Science\n",
      "\n",
      "### 1. **Statistics and Mathematics**\n",
      "Statistics provide the theoretical foundation for data science, including methods for data collection, analysis, and interpretation. Key statistical concepts include:\n",
      "\n",
      "- **Descriptive Statistics:** Summarizing data through measures like mean, median, mode, standard deviation, etc.\n",
      "- **Inferential Statistics:** Making predictions or inferences about a population from a sample set of data.\n",
      "- **Probability Theory:** Understanding the likelihood of events occurring, which is crucial for machine learning models.\n",
      "- **Linear Algebra and Calculus:** Essential for understanding more complex machine learning algorithms.\n",
      "\n",
      "### 2. **Data Exploration and Preprocessing**\n",
      "Before applying any model, data scientists must explore and preprocess the data:\n",
      "\n",
      "- **Data Cleaning:** Handling missing values, removing duplicates, and correcting errors.\n",
      "- **Data Transformation:** Normalizing, scaling, and encoding data to fit the requirements of algorithms.\n",
      "- **Feature Selection:** Choosing the most relevant variables for analysis.\n",
      "- **Exploratory Data Analysis (EDA):** Using visualizations and statistical methods to understand the data.\n",
      "\n",
      "### 3. **Machine Learning**\n",
      "Machine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable systems to improve their performance on tasks with experience. It includes:\n",
      "\n",
      "- **Supervised Learning:** Training models on labeled data (e.g., Regression, Classification).\n",
      "- **Unsupervised Learning:** Finding patterns in data without pre-existing labels (e.g., Clustering, Association).\n",
      "- **Semi-supervised Learning:** A mix of labeled and unlabeled data.\n",
      "- **Reinforcement Learning:** Training models to make a sequence of decisions by rewarding desired behaviors.\n",
      "\n",
      "### 4. **Programming**\n",
      "Proficiency in programming is essential for building and implementing models. Common programming languages include:\n",
      "\n",
      "- **Python:** Widely used for its simplicity and powerful libraries like Pandas, NumPy, scikit-learn, and TensorFlow.\n",
      "- **R:** Popular for statistical analysis and visualization with libraries like ggplot2 and caret.\n",
      "- **SQL:** Necessary for managing and querying large datasets.\n",
      "\n",
      "### 5. **Data Visualization**\n",
      "Communicating results and insights through visual means is critical. Tools and libraries such as:\n",
      "\n",
      "- **Matplotlib and Seaborn** (Python)\n",
      "- **ggplot2** (R)\n",
      "- **Tableau and Power BI** (Business Intelligence tools)\n",
      "\n",
      "are commonly used for creating effective visualizations.\n",
      "\n",
      "### 6. **Domain Expertise**\n",
      "Understanding the domain helps in asking the right questions and interpreting the results accurately.\n",
      "\n",
      "## Workflow of a Data Science Project\n",
      "\n",
      "1. **Problem Understanding:** Clearly define the problem and understand the business or research context.\n",
      "2. **Data Collection:** Gather data from various sources, which may include databases, APIs, or data scraping.\n",
      "3. **Data Processing:** Clean and organize the data to ensure it is usable for analysis.\n",
      "4. **Exploratory Data Analysis (EDA):** Perform initial investigations to understand the data's features.\n",
      "5. **Feature Engineering:** Create new features from existing data to improve model performance.\n",
      "6. **Model Building:** Develop machine learning models to make predictions or find patterns.\n",
      "7. **Model Evaluation:** Use metrics to assess the performance of the models.\n",
      "8. **Model Deployment:** Implement the model into a production environment.\n",
      "9. **Communication:** Present findings and recommendations to stakeholders.\n",
      "\n",
      "## Essential Tools and Technologies\n",
      "\n",
      "- **Libraries/Frameworks:** TensorFlow, Keras, PyTorch for deep learning; scikit-learn, xgboost for machine learning.\n",
      "- **Data Storage:** Databases like PostgreSQL, MongoDB; data storage solutions like Hadoop HDFS, cloud storage.\n",
      "- **ETL Processes:** Extract, Transform, Load processes and tools like Apache Nifi, Talend.\n",
      "- **Version Control:** Git for tracking changes in code and collaboration.\n",
      "\n",
      "## Ethical Considerations\n",
      "\n",
      "Data science also involves a strong ethical component, including:\n",
      "\n",
      "- **Data Privacy:** Ensuring that data is handled with care to protect individual privacy.\n",
      "- **Bias and Fairness:** Being aware of and mitigating biases in data and algorithms.\n",
      "- **Transparency:** Making the data science process clear to stakeholders.\n",
      "- **Accountability:** Taking responsibility for the outcomes of data science applications.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The basics of data science provide a solid foundation for understanding complex concepts and techniques that are applied in the field. It is a continuously evolving area, with new methodologies and tools emerging regularly. A successful data scientist must not only understand these basics but also stay updated with the latest trends and practices, ensuring ethical standards are met while"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_community.chat_models import ChatMaritalk\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "llm = ChatMaritalk(\n",
    "    model=MARITALK_LLM_MODEL,\n",
    "    api_key=MARITALK_API_KEY,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant!\"),\n",
    "    ]\n",
    ")\n",
    "print(chat_prompt)\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Write a document about the basics of data science.\",\n",
    "    )\n",
    "]\n",
    "print(messages)\n",
    "\n",
    "chain = chat_prompt | llm | output_parser\n",
    "\n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
